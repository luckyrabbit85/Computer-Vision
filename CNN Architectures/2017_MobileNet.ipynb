{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0f61d9",
   "metadata": {},
   "source": [
    "# Mobilenet\n",
    "\n",
    "MobileNet is a simple but efficient and not very computationally intensive convolutional neural networks for mobile vision applications. MobileNet is widely used in many real-world applications which includes object detection, fine-grained classifications, face attributes, and localization.\n",
    "\n",
    "MobileNet introduces **Depth-wise separable convolutions** namely,\n",
    "\n",
    "+ Depth-wise convolution\n",
    "+ Point-wise convolution\n",
    "\n",
    "\n",
    "The Depth-wise separable convolution is comprising of two layers, the depth-wise convolution, and the point-wise convolution. Basically the first layer is used to filter the input channels and the second layer is used to combine them to create a new feature.\n",
    "\n",
    "In the figure below we can see the working of these convolutions and how they decrease the cost of computation.\n",
    "\n",
    "![](./fig/dsc.png)\n",
    "\n",
    "The entire Network Structure\n",
    "\n",
    "![](./fig/mobile.png)\n",
    "\n",
    "Left: Standard Convolution followed by batch normalization and RELU. Right: Depthwise convolution layer and pointwise convolution layer, each followed by batch normalization and RELU.\n",
    "\n",
    "![](./fig/st.png)\n",
    "\n",
    "From the above image, we can see that every convolution layer followed by a batch normalization and a ReLU. Also, a final average pooling is been introduced just before the fully connected layer to reduce the spatial dimension to 1.\n",
    "Note that the above architecture has 28 layers by counting widthwise and pointwise convolution as separate layers.\n",
    "\n",
    "### Parameters of MobileNet\n",
    "\n",
    "Although the base MobileNet architecture is already small and computationally not very intensive, it has two different global hyperparameters to effectively reduce the computational cost further. One is the width multiplayer and another is the resolution wise multiplayer.\n",
    "\n",
    "+ **Width Multiplier: Thinner Models**\n",
    "For further reduction of computational cost, they introduced a simple parameter called Width Multiplier also refer as α.\n",
    "For each layer, the width multiplier α will be multiplied with the input and the output channels(N and M) in order to narrow a network. Computational Cost: Depthwise separable convolution with width multiplier\n",
    "Here α will vary from 0 to 1, with typical values of [1, 0.75, 0.5 and 0.25]. When α = 1, called as baseline MobileNet and α < 1, called as reduced MobileNet. Width Multiplier has the effect of reducing computational cost by α².\n",
    "\n",
    "\n",
    "+ **Resolution Multiplier: Reduced Representation**\n",
    "The second parameter to reduce the computational cost effectively. Also known as ρ.\n",
    "For a given layer, the resolution multiplier ρ will be multiplied with the input feature map. Now we can express the computational cost by applying width multiplier and resolution multiplier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ab4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
