{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF2 Quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253d42ea-fd55-4181-e35b-fff4886c5e08"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras import Input, datasets, layers, models, Model\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "# MNIST Handwritten Digit Classification Dataset\n",
        "\n",
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv9PirB3tLgL",
        "outputId": "2660f537-d612-485b-bc35-e3d7599add28"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGHobUTRtR6k"
      },
      "source": [
        "We have 60000 samples for training dataset and 10000 samples for testing dataset. Lets take 10000 samples from training data and keep them for validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZDmFTQatRKS"
      },
      "source": [
        "x_train, y_train = x_train[:-10000], y_train[:-10000]\n",
        "x_val, y_val = x_train[-10000:], y_train[-10000:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sml8TjauQRp"
      },
      "source": [
        "Check the data type of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH_ReXtRaq7-",
        "outputId": "84595773-8520-458b-93bb-e6c3794070b2"
      },
      "source": [
        "type(x_train), type(y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFwFLxLFkCTd"
      },
      "source": [
        "Normalizing the data to range [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3MzUazmj3Uc"
      },
      "source": [
        "x_train, x_val, x_test = x_train / 255.0, x_val / 225.0, x_test / 255.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHqb7e9xoJf"
      },
      "source": [
        "Inspecting the shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vVGOX3bkMI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696c1a1c-b923-4418-a6de-9eed96c1da8c"
      },
      "source": [
        "x_train.shape, x_val.shape, x_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 28, 28), (10000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93lbk-t1kSSc"
      },
      "source": [
        "Adding one more dimension for channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRQGaxrnmJk8"
      },
      "source": [
        "x_train = x_train[:,:,:,tf.newaxis].astype(\"float32\")\n",
        "x_val = x_val[:,:,:,tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[:,:,:,tf.newaxis].astype(\"float32\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSeyYqFwmW6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70375c80-c598-492d-b5cf-42dabaffc9c8"
      },
      "source": [
        "x_train.shape, x_val.shape, x_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 28, 28, 1), (10000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H8jlQHhOWBp"
      },
      "source": [
        "# Comparable Modelling Strategies in TensorFlow 2\n",
        "In TF.Keras there are basically three-way we can define a neural network, namely\n",
        "* Sequential API\n",
        "* Functional API\n",
        "* Model Subclassing API\n",
        "\n",
        "Among them, Sequential API is the easiest way to implement but comes with certain limitations. For example, with this API, we can't create a model that shares feature information to another layer except to its subsequent layer. In addition, multiple input and output are not possible to implement either.\n",
        "\n",
        "In this point, Functional API does solve these issues greatly. A model like Inception or ResNet is feasible to implement in Functional API. But often deep learning researcher wants to have more control over every nuance of the network and on the training pipelines and that's exactly what Model Subclassing API serves. Model Sub-Classing is a fully customizable way to implement the feed-forward mechanism for our custom-designed deep neural network in an object-oriented fashion.\n",
        "\n",
        "Let's create a very basic neural network using these three API. It will be the same neural architecture and will see what are the implementation differences. This of course will not demonstrate the full potential, especially for Functional and Model Sub-Classing API. The architecture will be as follows:\n",
        "\n",
        "`Input -> Conv -> MaxPool -> BN -> Conv -> BN -> Droput -> GAP -> Dense`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS8qT6ZrKaG2"
      },
      "source": [
        "input_dim = (28, 28, 1)\n",
        "output_dim = (10)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxeR0HuqJFB1"
      },
      "source": [
        "Build the `tf.keras` model using the Keras model [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7rUXYTnFSpa"
      },
      "source": [
        "seq_model = tf.keras.Sequential()\n",
        "# Declare input Shape \n",
        "seq_model.add(Input(shape=input_dim))\n",
        "\n",
        "# Block 1\n",
        "seq_model.add(Conv2D(32, 3, strides=2, activation=\"relu\"))\n",
        "seq_model.add(MaxPooling2D(3))\n",
        "seq_model.add(BatchNormalization())\n",
        "\n",
        "# Block 2\n",
        "seq_model.add(Conv2D(64, 3, activation=\"relu\"))\n",
        "seq_model.add(BatchNormalization())\n",
        "seq_model.add(Dropout(0.3))\n",
        "\n",
        "# Now that we apply global max pooling.\n",
        "seq_model.add(GlobalMaxPooling2D())\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "seq_model.add(Dense(output_dim))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOImmoSUFSO4",
        "outputId": "0dc4f0e1-b3f2-4e98-dda0-e4989b241473"
      },
      "source": [
        "seq_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 2, 2, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 19,850\n",
            "Trainable params: 19,658\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLQHuujfLzTd"
      },
      "source": [
        "Build the `tf.keras` model using the Keras model [Functional API](https://www.tensorflow.org/guide/keras/functional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2ynTj0BMWWK"
      },
      "source": [
        "# Declare input shape \n",
        "input = tf.keras.Input(shape=(input_dim))\n",
        "\n",
        "# Block 1\n",
        "x = Conv2D(32, 3, strides=2, activation=\"relu\")(input)\n",
        "x = MaxPooling2D(3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Block 2\n",
        "x = Conv2D(64, 3, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Now that we apply global max pooling.\n",
        "gap = GlobalMaxPooling2D()(x)\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "output = Dense(output_dim)(gap)\n",
        "\n",
        "# bind all\n",
        "func_model = Model(input, output)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcX1kULYMpCD",
        "outputId": "fe277535-b3ca-4546-952f-caff99ec92dd"
      },
      "source": [
        "func_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 19,850\n",
            "Trainable params: 19,658\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "class ModelSubClassing(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ModelSubClassing, self).__init__()\n",
        "        # Define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.conv1 = Conv2D(32, 3, strides=2, activation=\"relu\")\n",
        "        self.max1  = MaxPooling2D(3)\n",
        "        self.bn1   = BatchNormalization()\n",
        "\n",
        "        # Layer of Block 2\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")\n",
        "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
        "        self.drop  = tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "        # GAP, followed by Classifier\n",
        "        self.gap   = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.dense = tf.keras.layers.Dense(num_classes)\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        # forward pass: block 1 \n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # forward pass: block 2 \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        # droput followed by gap and classifier\n",
        "        x = self.drop(x)\n",
        "        x = self.gap(x)\n",
        "        return self.dense(x)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIAMgP10905q",
        "outputId": "82b6f8eb-2b90-495e-a002-11e8021fd5ed"
      },
      "source": [
        "sub_model = ModelSubClassing(output_dim)\n",
        "sub_model.build(input_shape = (None, 24, 24, 1))\n",
        "sub_model.call(Input(shape=input_dim))\n",
        "sub_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_sub_classing\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 19,850\n",
            "Trainable params: 19,658\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RZgjirs6-JF"
      },
      "source": [
        "# Training - The standard Method\n",
        "\n",
        "+ model.compile()\n",
        "+ model.fit()\n",
        "+ model.evaluate()\n",
        "+ model.predict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WypuDJwyNhZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260bb848-ec9e-4f14-ff1a-5defafddb846"
      },
      "source": [
        "# compile \n",
        "print('Sequential API')\n",
        "seq_model.compile(\n",
        "          loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "          metrics   = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "# fit \n",
        "seq_model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
        "\n",
        "# evaluate\n",
        "print(\"Evaluating on validation data\")\n",
        "seq_model.evaluate(x_val, y_val)\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "# compile \n",
        "print('\\nFunctional API')\n",
        "func_model.compile(\n",
        "          loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "          metrics   = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "# fit \n",
        "func_model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
        "\n",
        "# evaluate\n",
        "print(\"Evaluating on validation data\")\n",
        "func_model.evaluate(x_val, y_val)\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "# compile \n",
        "print('\\nModel Sub-Classing API')\n",
        "sub_model = ModelSubClassing(10)\n",
        "sub_model.compile(\n",
        "          loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "          metrics   = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "# fit \n",
        "sub_model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
        "\n",
        "# evaluate\n",
        "print(\"Evaluating on validation data\")\n",
        "sub_model.evaluate(x_val, y_val)\n",
        "\n",
        "print(\"\\nFinished Training models\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential API\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 4ms/step - loss: 0.3196 - sparse_categorical_accuracy: 0.9019\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9587\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9661\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9701\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0836 - sparse_categorical_accuracy: 0.9737\n",
            "Evaluating on validation data\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9732\n",
            "\n",
            "Functional API\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1340 - sparse_categorical_accuracy: 0.9586\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9664\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9718\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9744\n",
            "Evaluating on validation data\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9838\n",
            "\n",
            "Model Sub-Classing API\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.9246\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9624\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9676\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9728\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9757\n",
            "Evaluating on validation data\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9867\n",
            "\n",
            "Finished Training models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KElvRSbXdXmW"
      },
      "source": [
        "model.predict() is the function we use to make single prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp7VFn_zff1z"
      },
      "source": [
        "# Custom Training\n",
        "\n",
        "For custom training we follow these steps:\n",
        "\n",
        "+ Set optimizer, loss functions and metrics.\n",
        "\n",
        "+ Run a loop for number of epochs\n",
        "\n",
        "  + Run a nested loop for each batch of each epoch:\n",
        "  + Work with `tf.GradientTape()` to calculate and record loss and to conduct backpropagation.\n",
        "  + Run the optimizer\n",
        "  + Calculate, record and print out the metric results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyLQHWWw1EoS"
      },
      "source": [
        "# Convert Numpy array to TF Dataset Object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWOFiAklrnII"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size = 50000).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "source": [
        "loss, optimizer = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), tf.keras.optimizers.Adam()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S55Uk3lhb33"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcFyNn5Y1y7J",
        "outputId": "d9787437-8f98-4e19-d305-7d388bded78c"
      },
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nStart of epoch {epoch}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = sub_model(x_batch_train, training=True)  # Logits for this minibatch\n",
        "            loss_value = loss(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, sub_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, sub_model.trainable_weights))\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            print(f\"Training loss (for one batch) at step {step}: {round(float(loss_value), 4)}\")\n",
        "            print(f\"Seen so far: {((step + 1) * 32)} samples\")\n",
        "\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(f\"Training accuracy over epoch: {round(float(train_acc), 4)}\")\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = sub_model(x_batch_val, training=False)\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(f\"Validation accuracy:{round(float(train_acc), 4)}\")\n",
        "    print(f\"Time taken:{(time.time() - start_time)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.0921\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0521\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.3219\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0439\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0331\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.1172\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0103\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.013\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9755\n",
            "Validation accuracy:0.9755\n",
            "Time taken:32.84599494934082\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.0129\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.2852\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0655\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0161\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0237\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.1119\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0043\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0377\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9784\n",
            "Validation accuracy:0.9784\n",
            "Time taken:32.6999933719635\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.0871\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0422\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0515\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.1436\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0256\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0375\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0084\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0628\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9794\n",
            "Validation accuracy:0.9794\n",
            "Time taken:32.27415990829468\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0085\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0038\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0368\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0077\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0728\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0443\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0222\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0138\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.98\n",
            "Validation accuracy:0.98\n",
            "Time taken:32.09598636627197\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0967\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0101\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0229\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0394\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0986\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0062\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.3307\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.2136\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9805\n",
            "Validation accuracy:0.9805\n",
            "Time taken:32.17753720283508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sACM_SAhSKjg"
      },
      "source": [
        "# Speeding-up training step with `tf.function`\n",
        "\n",
        "The default runtime in TensorFlow 2 is eager execution. As such, our training loop above executes eagerly.\n",
        "\n",
        "This is great for debugging, but graph compilation has a definite performance advantage. Describing the computation as a static graph enables the framework to apply global performance optimizations. This is impossible when the framework is constrained to greedly execute one operation after another, with no knowledge of what comes next.\n",
        "\n",
        "You can compile into a static graph any function that takes tensors as input.  \n",
        "Just add a @tf.function decorator on it, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KItWPLbI1y4L"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = sub_model(x, training=True)\n",
        "        loss_value = loss(y, logits)\n",
        "    grads = tape.gradient(loss_value, sub_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, sub_model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzKMJv1a1y1r"
      },
      "source": [
        "@tf.function\n",
        "def val_step(x, y):\n",
        "    val_logits = sub_model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqSaSil21yy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b55a5f-fcda-4450-fdf5-b39b2ffb36c3"
      },
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nStart of epoch {epoch}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "  \n",
        "        if step % 200 == 0:\n",
        "            print(f\"Training loss (for one batch) at step {step}: {round(float(loss_value), 4)}\")\n",
        "            print(f\"Seen so far: {((step + 1) * 32)} samples\")\n",
        "\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(f\"Training accuracy over epoch: {round(float(train_acc), 4)}\")\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "       val_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(f\"Validation accuracy:{round(float(train_acc), 4)}\")\n",
        "    print(f\"Time taken:{(time.time() - start_time)}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.1273\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.1019\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0085\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.1863\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0096\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0799\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0116\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0339\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.982\n",
            "Validation accuracy:0.982\n",
            "Time taken:5.274996280670166\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.0371\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0373\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0076\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0958\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0078\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0221\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0844\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.1299\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9826\n",
            "Validation accuracy:0.9826\n",
            "Time taken:4.607251405715942\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.0116\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0181\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0072\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0896\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0301\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0135\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0067\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0546\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9824\n",
            "Validation accuracy:0.9824\n",
            "Time taken:4.6322643756866455\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0192\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.0339\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0109\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.0333\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.1346\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0274\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0154\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.0361\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9834\n",
            "Validation accuracy:0.9834\n",
            "Time taken:4.537444829940796\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0198\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 200: 0.1829\n",
            "Seen so far: 6432 samples\n",
            "Training loss (for one batch) at step 400: 0.0606\n",
            "Seen so far: 12832 samples\n",
            "Training loss (for one batch) at step 600: 0.1951\n",
            "Seen so far: 19232 samples\n",
            "Training loss (for one batch) at step 800: 0.0112\n",
            "Seen so far: 25632 samples\n",
            "Training loss (for one batch) at step 1000: 0.0029\n",
            "Seen so far: 32032 samples\n",
            "Training loss (for one batch) at step 1200: 0.0726\n",
            "Seen so far: 38432 samples\n",
            "Training loss (for one batch) at step 1400: 0.056\n",
            "Seen so far: 44832 samples\n",
            "Training accuracy over epoch: 0.9839\n",
            "Validation accuracy:0.9839\n",
            "Time taken:4.623131275177002\n"
          ]
        }
      ]
    }
  ]
}